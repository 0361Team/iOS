//
//  AudioStream.swift
//  Lecture2Quiz
//
//  Created by ë°”ê²¬ê·œ on 4/27/25.
//

import AVFoundation


class AudioStreamer {
    private let engine = AVAudioEngine()
    private let inputNode: AVAudioInputNode
    private var inputFormat: AVAudioFormat?
    private var isPaused: Bool = false
    private var audioWebSocket: AudioWebSocket?

    private var converter: AVAudioConverter?
    
    // WhisperLive ì„¤ì •ì— ë§ì¶˜ í¬ë§·
    private var bufferSize: AVAudioFrameCount = 4096
    private var sampleRate: Double = 16000
    private var channels: UInt32 = 1

    init(webSocket: AudioWebSocket) {
        self.inputNode = engine.inputNode
        self.audioWebSocket = webSocket
    }

    // MARK: - ì˜¤ë””ì˜¤ ì„¸ì…˜ ì„¤ì •
    func configureAudioSession() {
        let session = AVAudioSession.sharedInstance()
        do {
            // ğŸ§ ë¸”ë£¨íˆ¬ìŠ¤ ì¥ì¹˜ í¬í•¨í•˜ì—¬ ì˜¤ë””ì˜¤ ì¬ìƒ ë° ë…¹ìŒ ì„¤ì •
            try session.setCategory(.playAndRecord, mode: .voiceChat, options: [.allowBluetooth, .defaultToSpeaker])
            try session.setActive(true)

            // ğŸ” ì‚¬ìš© ê°€ëŠ¥í•œ ì˜¤ë””ì˜¤ ì…ë ¥ ë””ë°”ì´ìŠ¤ íƒìƒ‰
            if let availableInputs = session.availableInputs {
                for input in availableInputs {
                    print("ğŸ” ì…ë ¥ ë””ë°”ì´ìŠ¤ ë°œê²¬: \(input.portType.rawValue)")
                    if input.portType == .bluetoothHFP || input.portType == .bluetoothLE {
                        try session.setPreferredInput(input)
                        print("ğŸ§ ì—ì–´íŒŸì´ ì…ë ¥ ë””ë°”ì´ìŠ¤ë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    }
                }
            }

            // âœ… ì‹¤ì œ í•˜ë“œì›¨ì–´ í¬ë§· ê°€ì ¸ì˜¤ê¸°
            sampleRate = session.sampleRate
            channels = UInt32(session.inputNumberOfChannels)
            print("ğŸ™ï¸ ì„¤ì •ëœ ìƒ˜í”Œë ˆì´íŠ¸: \(sampleRate)")
            print("ğŸ™ï¸ ì„¤ì •ëœ ì±„ë„ ìˆ˜: \(channels)")

        } catch {
            print("ğŸ”´ ì˜¤ë””ì˜¤ ì„¸ì…˜ ì„¤ì • ì‹¤íŒ¨: \(error.localizedDescription)")
        }
    }

    // MARK: - ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘
    func startStreaming() {
        configureAudioSession()
        
        // âœ… í•˜ë“œì›¨ì–´ í¬ë§·ì— ë§ì¶° Tap í¬ë§· ì„¤ì •
        let inputFormat = inputNode.inputFormat(forBus: 0)
        print("ğŸ” Input Format: \(inputFormat)")

        guard let outputFormat = AVAudioFormat(commonFormat: .pcmFormatInt16,
                                               sampleRate: 16000,
                                               channels: 1,
                                               interleaved: true) else {
            print("âš ï¸ AVAudioFormat ìƒì„± ì‹¤íŒ¨")
            return
        }

        // âœ… Converter ìƒì„±
        guard let audioConverter = AVAudioConverter(from: inputFormat, to: outputFormat) else {
            print("ğŸ”´ Converter ì´ˆê¸°í™” ì‹¤íŒ¨")
            return
        }
        
        // ğŸ”„ ì—¬ê¸°ì„œ converterì— ê°’ì„ í• ë‹¹í•´ì•¼ í•¨
        self.converter = audioConverter

        print("âœ… Converter ì´ˆê¸°í™” ì„±ê³µ")

        inputNode.installTap(onBus: 0, bufferSize: bufferSize, format: inputFormat) { [weak self] buffer, _ in
            self?.processAudioBuffer(buffer)
        }

        do {
            try engine.start()
            print("ğŸ™ï¸ AVAudioEngine ì‹œì‘ë¨")
        } catch {
            print("ğŸ”´ AVAudioEngine ì‹œì‘ ì‹¤íŒ¨: \(error.localizedDescription)")
        }
    }



    // MARK: - ì˜¤ë””ì˜¤ ë²„í¼ë¥¼ WebSocketìœ¼ë¡œ ì„œë²„ë¡œ ì „ì†¡
    func processAudioBuffer(_ buffer: AVAudioPCMBuffer) {
        guard let converter = converter else { return }

        let outputBuffer = AVAudioPCMBuffer(pcmFormat: converter.outputFormat, frameCapacity: buffer.frameCapacity)!
        var error: NSError?

        let inputBlock: AVAudioConverterInputBlock = { inNumPackets, outStatus in
            outStatus.pointee = .haveData
            return buffer
        }

        converter.convert(to: outputBuffer, error: &error, withInputFrom: inputBlock)

        if let error = error {
            print("ğŸ”´ ë³€í™˜ ì¤‘ ì—ëŸ¬: \(error.localizedDescription)")
            return
        }

        // ë¨¼ì € 16ë¹„íŠ¸ PCMìœ¼ë¡œ ë³€í™˜ í›„ Float32ë¡œ ë‹¤ì‹œ ë³€í™˜
        if let pcmData = convertBufferTo16BitPCM(outputBuffer) {
            // Float32ë¡œ ë³€í™˜í•˜ì—¬ ì„œë²„ì— ì „ì†¡
            let floatData = convertPCMToFloat32(pcmData)
            print("ğŸ”„ Float32 ë°ì´í„° ì „ì†¡ ì¤‘...")
            audioWebSocket?.sendDataToServer(floatData)
        } else {
            print("Error: Audio buffer ë³€í™˜ ì‹¤íŒ¨")
        }
    }

    // MARK: - 32bit float PCM -> 16bit int PCM ë³€í™˜
    func convertBufferTo16BitPCM(_ buffer: AVAudioPCMBuffer) -> Data? {
        guard let channelData = buffer.int16ChannelData else {
            print("int16ChannelData is nil")
            return nil
        }
        let channelPointer = channelData.pointee
        let dataLength = Int(buffer.frameLength) * MemoryLayout<Int16>.size
        return Data(bytes: channelPointer, count: dataLength)
    }
    
    // MARK: - 16bit int PCM -> Float32 ë³€í™˜ (ìƒˆë¡œ ì¶”ê°€)
    func convertPCMToFloat32(_ pcmData: Data) -> Data {
        // 16ë¹„íŠ¸ PCM ë°ì´í„°ë¥¼ float32ë¡œ ë³€í™˜
        var floatArray = [Float32](repeating: 0, count: pcmData.count / 2)
        
        pcmData.withUnsafeBytes { (bytes: UnsafeRawBufferPointer) -> Void in
            if let baseAddress = bytes.baseAddress {
                let int16Buffer = baseAddress.bindMemory(to: Int16.self, capacity: pcmData.count / 2)
                for i in 0..<pcmData.count / 2 {
                    // -1.0ì—ì„œ 1.0 ì‚¬ì´ë¡œ ì •ê·œí™” (Python ì½”ë“œì™€ ë™ì¼í•œ ì²˜ë¦¬)
                    floatArray[i] = Float32(int16Buffer[i]) / 32768.0
                }
            }
        }
        
        // Float32 ë°°ì—´ì„ Dataë¡œ ë³€í™˜
        return Data(bytes: floatArray, count: floatArray.count * MemoryLayout<Float32>.size)
    }

    // MARK: - ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë° ì¼ì‹œ ì •ì§€
    func pauseStreaming() {
        guard !isPaused else { return }
        inputNode.removeTap(onBus: 0)
        isPaused = true
    }

    // MARK: - ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë° ì¬ê°œ
    func resumeStreaming() {
        guard isPaused else { return }
        guard let inputFormat = inputFormat else {
            print("inputFormatì´ nilì…ë‹ˆë‹¤.")
            return
        }

        inputNode.installTap(onBus: 0, bufferSize: bufferSize, format: inputFormat) { [weak self] buffer, _ in
            self?.processAudioBuffer(buffer)
        }
        isPaused = false
    }

    // MARK: - ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì§€
    func stopStreaming() {
        inputNode.removeTap(onBus: 0)
        engine.stop()
        print("ğŸ›‘ AVAudioEngine ì¤‘ì§€ë¨")
    }
    
    
}
