//  AudioStream.swift
//  Lecture2Quiz
//
//  Created by ë°”ê²¬ê·œ on 4/27/25.
//

import AVFoundation

class AudioStreamer {
    private let engine = AVAudioEngine()
    private let inputNode: AVAudioInputNode
    private var inputFormat: AVAudioFormat?
    private var isPaused: Bool = false
    private var audioWebSocket: AudioWebSocket?
    private var partialBuffer = Data() // ğŸ”„ ë‚¨ì€ ì²­í¬ ë³´ê´€

    // WhisperLive ì„¤ì •ì— ë§ì¶˜ í¬ë§·
    private var bufferSize: AVAudioFrameCount = 1600  // 100ms ê¸°ì¤€
    private var sampleRate: Double = 16000
    private var channels: UInt32 = 1

    // ğŸ”„ ë¦¬ìƒ˜í”Œë§ì„ ìœ„í•œ ì˜¤ë””ì˜¤ ì»¨ë²„í„°
    private var converter: AVAudioConverter?

    init(webSocket: AudioWebSocket) {
        self.inputNode = engine.inputNode
        self.audioWebSocket = webSocket
        
        // ğŸ’¡ ë¦¬ìƒ˜í”Œë§ í¬ë§· ì„¤ì •
        let inputFormat = inputNode.outputFormat(forBus: 0)
        print("ğŸ” ì…ë ¥ í¬ë§·: \(inputFormat)")

        // ğŸ”„ WhisperLiveê°€ ê¸°ëŒ€í•˜ëŠ” 16kHz Int16 í¬ë§· ìƒì„±
        let outputFormat = AVAudioFormat(commonFormat: .pcmFormatInt16,
                                         sampleRate: 16000,
                                         channels: 1,
                                         interleaved: true)!
        
        // ğŸ”„ ì˜¤ë””ì˜¤ ë³€í™˜ê¸° ìƒì„±
        self.converter = AVAudioConverter(from: inputFormat, to: outputFormat)
        self.inputFormat = outputFormat
    }

    // MARK: - ì˜¤ë””ì˜¤ ì„¸ì…˜ ì„¤ì •
    func configureAudioSession() {
        let session = AVAudioSession.sharedInstance()
        do {
            try session.setCategory(.playAndRecord, mode: .default, options: [.allowBluetooth, .defaultToSpeaker])
            try session.setPreferredSampleRate(48000)
            try session.setPreferredInputNumberOfChannels(1) // Monoë¡œ ê°•ì œ ì„¤ì •
            try session.setMode(.measurement)
            try session.setActive(true, options: .notifyOthersOnDeactivation)
            sampleRate = session.sampleRate
            channels = UInt32(session.inputNumberOfChannels)
            print("ğŸ™ï¸ ì„¤ì •ëœ ìƒ˜í”Œë ˆì´íŠ¸: \(sampleRate)")
            print("ğŸ™ï¸ ì„¤ì •ëœ ì±„ë„ ìˆ˜: \(channels)")
        } catch {
            print("ğŸ”´ ì˜¤ë””ì˜¤ ì„¸ì…˜ ì„¤ì • ì‹¤íŒ¨: \(error.localizedDescription)")
        }
    }

    // MARK: - ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘
    func startStreaming() {
        configureAudioSession()
        
        let format = AVAudioFormat(commonFormat: .pcmFormatFloat32,
                                   sampleRate: 48000,
                                   channels: channels,
                                   interleaved: true)
        
        guard let hardwareFormat = format else {
            print("âš ï¸ ì˜¤ë””ì˜¤ í¬ë§· ìƒì„± ì‹¤íŒ¨")
            return
        }

        self.inputFormat = hardwareFormat
        
        inputNode.installTap(onBus: 0, bufferSize: bufferSize, format: hardwareFormat) { [weak self] buffer, _ in
            self?.processAudioBuffer(buffer)
        }

        do {
            try engine.start()
            print("ğŸ™ï¸ AVAudioEngine ì‹œì‘ë¨")
        } catch {
            print("ğŸ”´ AVAudioEngine ì‹œì‘ ì‹¤íŒ¨: \(error.localizedDescription)")
        }
    }

    // MARK: - ì˜¤ë””ì˜¤ ë²„í¼ë¥¼ WebSocketìœ¼ë¡œ ì „ì†¡
    func processAudioBuffer(_ buffer: AVAudioPCMBuffer) {
        guard let converter = self.converter else {
            print("âŒ ì˜¤ë””ì˜¤ ì»¨ë²„í„° ìƒì„± ì‹¤íŒ¨")
            return
        }

        // ğŸ” **RMS ê³„ì‚°**
        if let floatChannelData = buffer.floatChannelData {
            let frameLength = Int(buffer.frameLength)
            let channelDataValue = Array(UnsafeBufferPointer(start: floatChannelData.pointee, count: frameLength))
            
            // ğŸ”„ RMS ê³„ì‚°
            let rms = sqrt(channelDataValue.map { $0 * $0 }.reduce(0, +) / Float(frameLength))
            print("ğŸ”Š ì˜¤ë””ì˜¤ RMS ê°’: \(rms)")
            
            // ğŸ” ë„ˆë¬´ ì‘ìœ¼ë©´ ê²½ê³  ë¡œê·¸ ì¶œë ¥
            if rms < 0.01 {
                print("âš ï¸ ë³¼ë¥¨ì´ ë„ˆë¬´ ì‘ìŠµë‹ˆë‹¤.")
            }
        }

        let outputFormat = AVAudioFormat(commonFormat: .pcmFormatInt16,
                                         sampleRate: 16000,
                                         channels: 1,
                                         interleaved: true)!

        guard let newBuffer = AVAudioPCMBuffer(pcmFormat: outputFormat, frameCapacity: 1600) else {
            print("âŒ PCM Buffer ìƒì„± ì‹¤íŒ¨")
            return
        }

        let inputBlock: AVAudioConverterInputBlock = { _, outStatus in
            outStatus.pointee = .haveData
            return buffer
        }

        var error: NSError?
        converter.convert(to: newBuffer, error: &error, withInputFrom: inputBlock)

        if let error = error {
            print("âŒ ì˜¤ë””ì˜¤ ë³€í™˜ ì‹¤íŒ¨: \(error.localizedDescription)")
            return
        }

        print("ğŸ“ ë³€í™˜ëœ Buffer Frame Length: \(newBuffer.frameLength), Sample Rate: \(newBuffer.format.sampleRate)")

        if let audioData = convertToFloat32BytesLikePython(newBuffer) {
            var completeData = partialBuffer + audioData
            let chunkSize = 4096

            while completeData.count >= chunkSize {
                let chunk = completeData.prefix(chunkSize)
                audioWebSocket?.sendDataToServer(chunk)
                print("ğŸ”„ ì˜¤ë””ì˜¤ ë°ì´í„° ì „ì†¡ ì„±ê³µ: 4096 ë°”ì´íŠ¸")
                completeData.removeFirst(chunkSize)
            }

            partialBuffer = completeData
        }
    }



    // MARK: - Pythonì˜ bytes_to_float_array ë©”ì†Œë“œì™€ ìœ ì‚¬í•˜ê²Œ ë³€í™˜
    func convertToFloat32BytesLikePython(_ buffer: AVAudioPCMBuffer) -> Data? {
        guard let int16ChannelData = buffer.int16ChannelData else {
            print("int16ChannelData is nil")
            return nil
        }

        let frameLength = Int(buffer.frameLength)
        let channelPointer = int16ChannelData.pointee
        
        // Float32 ë°°ì—´ ìƒì„±
        var floatArray = [Float32](repeating: 0, count: frameLength)
        
        // Int16 -> Float32 ì •ê·œí™” (Pythonê³¼ ë™ì¼í•œ ë°©ì‹)
        for i in 0..<frameLength {
            let int16Value = channelPointer[i]
            // Pythonì˜ ì •ê·œí™” ë°©ì‹: value.astype(np.float32) / 32768.0
            floatArray[i] = Float32(Int16(littleEndian: int16Value)) / 32768.0

        }
        
        // Float32 ë°°ì—´ì„ ë°”ì´íŠ¸ë¡œ ë³€í™˜ (Pythonì˜ tobytes()ì™€ ë™ì¼)
        let floatData = Data(bytes: floatArray, count: frameLength * MemoryLayout<Float32>.size)
        
        print("ğŸ”„ Python ìŠ¤íƒ€ì¼ë¡œ Float32ë¡œ ë³€í™˜ ì™„ë£Œ - \(floatData.count) bytes")
        return floatData
    }

    // MARK: - ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë° ì¼ì‹œ ì •ì§€
    func pauseStreaming() {
        guard !isPaused else { return }
        inputNode.removeTap(onBus: 0)
        isPaused = true
        print("â¸ï¸ ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë° ì¼ì‹œ ì •ì§€ë¨")
    }

    // MARK: - ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë° ì¬ê°œ
    func resumeStreaming() {
        guard isPaused else { return }
        guard let inputFormat = inputFormat else {
            print("inputFormatì´ nilì…ë‹ˆë‹¤.")
            return
        }

        inputNode.installTap(onBus: 0, bufferSize: bufferSize, format: inputFormat) { [weak self] buffer, _ in
            self?.processAudioBuffer(buffer)
        }
        isPaused = false
        print("â–¶ï¸ ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë° ì¬ê°œë¨")
    }

    // MARK: - ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì§€
    func stopStreaming() {
        inputNode.removeTap(onBus: 0)
        engine.stop()
        print("ğŸ›‘ AVAudioEngine ì¤‘ì§€ë¨")
    }
}
