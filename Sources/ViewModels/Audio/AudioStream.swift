import AVFoundation

class AudioStreamer {
    private let engine = AVAudioEngine()
    private let inputNode: AVAudioInputNode
    private var inputFormat: AVAudioFormat?
    private var isPaused: Bool = false
    private var audioWebSocket: AudioWebSocket?
    private var converter: AVAudioConverter?

    // WhisperLive ì„¤ì •ì— ë§ì¶˜ í¬ë§·
    private var bufferSize: AVAudioFrameCount = 4096
    private var sampleRate: Double = 16000
    private var channels: UInt32 = 1

    init(webSocket: AudioWebSocket) {
        self.inputNode = engine.inputNode
        self.audioWebSocket = webSocket
    }

    // MARK: - ì˜¤ë””ì˜¤ ì„¸ì…˜ ì„¤ì •
    func configureAudioSession() {
        let session = AVAudioSession.sharedInstance()
        do {
            try session.setCategory(.playAndRecord, mode: .voiceChat, options: [.allowBluetooth, .defaultToSpeaker])
            try session.setActive(true)

            // ğŸ” ì‚¬ìš© ê°€ëŠ¥í•œ ì˜¤ë””ì˜¤ ì…ë ¥ ë””ë°”ì´ìŠ¤ íƒìƒ‰
            if let availableInputs = session.availableInputs {
                for input in availableInputs {
                    print("ğŸ” ì…ë ¥ ë””ë°”ì´ìŠ¤ ë°œê²¬: \(input.portType.rawValue)")
                    if input.portType == .bluetoothHFP || input.portType == .bluetoothLE {
                        try session.setPreferredInput(input)
                        print("ğŸ§ ì—ì–´íŒŸì´ ì…ë ¥ ë””ë°”ì´ìŠ¤ë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    }
                }
            }

            // âœ… ì‹¤ì œ í•˜ë“œì›¨ì–´ í¬ë§· ê°€ì ¸ì˜¤ê¸°
            let inputSampleRate = session.sampleRate
            let inputChannels = UInt32(session.inputNumberOfChannels)
            print("ğŸ™ï¸ ì„¤ì •ëœ ìƒ˜í”Œë ˆì´íŠ¸: \(inputSampleRate)")
            print("ğŸ™ï¸ ì„¤ì •ëœ ì±„ë„ ìˆ˜: \(inputChannels)")

            // âœ… ìƒ˜í”Œë ˆì´íŠ¸ë¥¼ 16000ìœ¼ë¡œ ë³€í™˜í•˜ë„ë¡ ì„¤ì •
            let inputFormat = AVAudioFormat(commonFormat: .pcmFormatFloat32, sampleRate: inputSampleRate, channels: inputChannels, interleaved: false)!
            let outputFormat = AVAudioFormat(commonFormat: .pcmFormatFloat32, sampleRate: 16000, channels: inputChannels, interleaved: false)!
            
            converter = AVAudioConverter(from: inputFormat, to: outputFormat)
            
        } catch {
            print("ğŸ”´ ì˜¤ë””ì˜¤ ì„¸ì…˜ ì„¤ì • ì‹¤íŒ¨: \(error.localizedDescription)")
        }
    }

    // MARK: - ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘
    func startStreaming() {
        configureAudioSession()
        
        let format = inputNode.outputFormat(forBus: 0)
        self.inputFormat = format

        
        self.inputFormat = format
        
        inputNode.installTap(onBus: 0, bufferSize: bufferSize, format: format) { [weak self] buffer, _ in
            self?.processAudioBuffer(buffer)
        }

        do {
            try engine.start()
            print("ğŸ™ï¸ AVAudioEngine ì‹œì‘ë¨")
        } catch {
            print("ğŸ”´ AVAudioEngine ì‹œì‘ ì‹¤íŒ¨: \(error.localizedDescription)")
        }
    }

    // MARK: - ì˜¤ë””ì˜¤ ë²„í¼ë¥¼ WebSocketìœ¼ë¡œ ì„œë²„ë¡œ ì „ì†¡
    func processAudioBuffer(_ buffer: AVAudioPCMBuffer) {
        guard let converter = converter else { return }

        let outputBuffer = AVAudioPCMBuffer(pcmFormat: converter.outputFormat, frameCapacity: buffer.frameCapacity)!
        var error: NSError?

        let inputBlock: AVAudioConverterInputBlock = { inNumPackets, outStatus in
            outStatus.pointee = .haveData
            return buffer
        }

        converter.convert(to: outputBuffer, error: &error, withInputFrom: inputBlock)

        if let error = error {
            print("ğŸ”´ ë³€í™˜ ì¤‘ ì—ëŸ¬: \(error.localizedDescription)")
            return
        }

        if let audioData = convertBufferTo16BitPCM(outputBuffer) {
            print("ğŸ”„ PCM ë°ì´í„° ì „ì†¡ ì¤‘...")
            audioWebSocket?.sendDataToServer(audioData)
        } else {
            print("Error: Audio buffer ë³€í™˜ ì‹¤íŒ¨")
        }
    }

    // MARK: - 32bit float PCM -> 16bit int PCM ë³€í™˜
    func convertBufferTo16BitPCM(_ buffer: AVAudioPCMBuffer) -> Data? {
        guard let floatChannelData = buffer.floatChannelData else {
            print("floatChannelData is nil")
            return nil
        }

        let channelPointer = floatChannelData.pointee
        let frameLength = Int(buffer.frameLength)
        var pcmData = Data(capacity: frameLength * MemoryLayout<Int16>.size)

        for i in 0..<frameLength {
            let sample = max(-1.0, min(1.0, channelPointer[i])) // í´ë¦¬í•‘ ì²˜ë¦¬
            var intSample = Int16(sample * Float(Int16.max))
            pcmData.append(Data(bytes: &intSample, count: MemoryLayout<Int16>.size))
        }

        return pcmData
    }

    // MARK: - ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë° ì¼ì‹œ ì •ì§€
    func pauseStreaming() {
        guard !isPaused else { return }
        inputNode.removeTap(onBus: 0)
        isPaused = true
    }

    // MARK: - ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë° ì¬ê°œ
    func resumeStreaming() {
        guard isPaused else { return }
        guard let inputFormat = inputFormat else {
            print("inputFormatì´ nilì…ë‹ˆë‹¤.")
            return
        }

        inputNode.installTap(onBus: 0, bufferSize: bufferSize, format: inputFormat) { [weak self] buffer, _ in
            self?.processAudioBuffer(buffer)
        }
        isPaused = false
    }

    // MARK: - ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì§€
    func stopStreaming() {
        inputNode.removeTap(onBus: 0)
        engine.stop()
        print("ğŸ›‘ AVAudioEngine ì¤‘ì§€ë¨")
    }
}

